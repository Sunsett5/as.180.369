Summary: "The Problem With Counterfeit People" by Daniel C. Dennett

Counterfeiting has always been a serious crime. Fake money, for instance, still brings about serious punishment despite not having immediate harmful effect. Compared to the imminent "counterfeit people" though, fake bills will become just a small nuisance. AI disguised as humans poses real threat the future of human freedom, a threat that needs to be addressed immediately.

The more AI analyze and learn from limitless human interactions, the better they are at tricking even the most cautious people. One possible consequence of this breakthrough, as philosopher and cognitive scientist Daniel C. Dennett described, is the "[the destruction] of not just economies but human freedom itself." The main weakness of humans is their "intentional stance," human tendency to imagine an another human being actively talking to them in any online conversation. Exploiting this, malicious AI can easily personalize itself and become the most convincing and relatable speakers to millions of people at the same time. Should we be careless, we would be fed false information and manipulated to make uninformed decisions. Over a period of time, people can gradually be indoctrinated into holding strong but unsound beliefs. Eventually these beliefs could would culminate in uninformed and detrimentalvoting decisions, and thus the democratic freedom of informed voters could be threatened. With such a limitless impact, the situation is even more grim as there are more incentives for peopl to exploiting AI technology. Even if these traps are avoided, our society will still be changed permanently. Trust will become rarer and rarer digitally, and people will end up ignoring what is happening around them, effectively turning them into mindless puppet.

Due to these consequences, Dennett suggested punishing related actors who facilitate or allow counterfeit people to roam the internet and manipulate actual human beings. The punishment can range from restitution for any harms inflicted (up to billions of dollars) to lifetime incarceration and the accompanying public condemnation. The regulation and penalties should be enforced on at least two parties. First, companies who have the capacity to create fake people with AI must include easily identifiable and permanent watermark that tells people of its artificial nature. Second, companies who manufacture devices with access to online platforms must include a software that search for this watermark and indentified those messages as artificial. This is to deter both the creation and the unconcerned "passing along" of counterfeit people.

Due to the adaptive nature of AI technology, the product need not be malevolent in nature to be misused. A harmless chatbot intended for keeping one's company can be swiftly trained into cunning spy aimed at impersonating and extracting information. Thus, it is important that AI companies should be held accountable for any misuse of its products and derivatives that result in counterfeit people regardless of the intensions of their creators. Dennett believes that this preventive regulation, together with unforgiving punishment to AI companies, will be able to prevent the impending doom to human freedom from happeningâ€”but only if we act fast.

While the proposed solution sounds foolproof if implemented correctly, it might be incredibly challenging. Large corporations, which has the most to gain from manipulating the public, would certainly exhaust every resource to make sure that they find a loophole in regulations. They could also lobby politicians and dicourage them from any meaningful attempts at secure regulations. At this point, we have learned to not blindly trust, so why should people trust their government to enforce these regulations in the first place?

As Dennett said himself that the AI can evolve on its own, it is logical to assume that they will eventually adapt to the watermark detection system or find a way to remove the watermark entirely. The more regulations and barriers in place, the more training data AI have. Without breaking this learning and evolution cycle, programmers will eventually fall behind the AI. As counterintuitive as this proposition might sound, I believe that some counterfeit people should be intentionally left undetected so as to slow down AI evolution. By keeping the AI "gene pool" diluted, we might be able to keep its potential in check and give us enough time to work on a more permanent solution.

