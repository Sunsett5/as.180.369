Summary: "The Problem With Counterfeit People" by Daniel C. Dennett

As dangerous as counterfeit money might have been, AI disguised as humans can be far more deadly to the future of human freedom. 
The more AI analyze and learn from limitless human interactions, the better they are at tricking even the most cautious people. One possible consequence of this breakthrough, as Dennett described, is the "[the destruction] of not just economies but human freedom itself." Exploiting "intentional stance," human tendency to turn any online conversations into actual individuals, malicious AI can become as the best natural speakers. Should we be careless, we would be fed false information and manipulated to make uninformed decisions. One of these decisions could be related to government policies, and thus the democratic freedom of informed voters could be threatened. While avoiding these pitfalls, we may stumble into a society where no trust can be formed digitally, and people end up ignoring what is happening around them.

Due to these consequences, Dennett suggested punishing related actors who facilitate or allow counterfeit people to roam the internet and manipulate actual human beings. The regulation and penalties should be implemented in two parts. First, companies who have the capacity to create fake people with AI must include easily identifiable and permanent watermark that tells people of its artificial nature. Second, companies who manufacture devices with access to online platforms must include a software that search for this watermark and indentified those messages as artificial. This is to deter both the creation and the unconcerned "passing along" of counterfeit people.

Due to the adaptive nature of AI technology, the product need not be malevolent in nature to be misused. Thus, it is important that AI companies should be held accountable for any misuse of its products and derivatives that result in counterfeit people regardless of the intensions of their creators. Dennett believes that this preventive regulation, together with unforgiving punishment to AI companies, will be able to prevent the impending doom to human freedom from happeningâ€”but only if we act fast.

While the proposed solution sounds foolproof if implemented correctly, it might be incredibly challenging. Large corporations, which has the most to gain from manipulating the public, would certainly exhaust every resource to make sure that they find a loophole in regulations. They could also lobby politicians and dicourage them from any meaningful attempts at secure regulations. At this point, we have learned to not blindly trust, so why should people trust their government to enforce these regulations in the first place?

As Dennett said himself that the AI can evolve on its own, it is logical to assume that they will eventually adapt to the watermark detection system or find a way to remove the watermark entirely. The more regulations and barriers in place, the more training data AI have. Without breaking this learning and evolution cycle, programmers will eventually fall behind the AI. As counterintuitive as this proposition might sound, I believe that some counterfeit people should be intentionally left undetected so as to slow down AI evolution. By keeping the AI "gene pool" diluted, we might be able to keep its potential in check and give us enough time to work on a more permanent solution.

